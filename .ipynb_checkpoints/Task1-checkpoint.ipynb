{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a10165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes = []\n",
    "train_words = []\n",
    "train_tags = []\n",
    "with open(\"data/train\") as f:\n",
    "    for l in f:\n",
    "        if l != \"\\n\":\n",
    "            l = l.strip()\n",
    "            index = l.split(\" \")[0]\n",
    "            word = l.split(\" \")[1]\n",
    "            tag = l.split(\" \")[2]\n",
    "            \n",
    "            train_indexes.append(index)\n",
    "            train_words.append(word)\n",
    "            train_tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fdd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_indexes = []\n",
    "dev_words = []\n",
    "dev_tags = []\n",
    "with open(\"data/dev\") as f:\n",
    "    for l in f:\n",
    "        if l != \"\\n\":\n",
    "            l = l.strip()\n",
    "            index = l.split(\" \")[0]\n",
    "            word = l.split(\" \")[1]\n",
    "            tag = l.split(\" \")[2]\n",
    "            \n",
    "            dev_indexes.append(index)\n",
    "            dev_words.append(word)\n",
    "            dev_tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7631675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(zip(train_indexes, train_words, train_tags), columns = [\"index\", \"word\", \"tag\"])\n",
    "dev_data = pd.DataFrame(zip(dev_indexes, dev_words, dev_tags), columns = [\"index\", \"word\", \"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18cdaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = train_data[\"word\"].values\n",
    "train_indexes = train_data[\"index\"].values\n",
    "train_pos_tags = train_data[\"tag\"].values\n",
    "train_words_dict = dict()\n",
    "\n",
    "# Count words in the training set.\n",
    "\n",
    "for word in train_words:\n",
    "    train_words_dict[word] = train_words_dict.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e8ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocab = dict()\n",
    "unknown_words = []\n",
    "\n",
    "# Find words with less than 3 occurences and store the counts.\n",
    "\n",
    "for word, count in train_words_dict.items():\n",
    "    if count <= 3:\n",
    "        unknown_words.append(word)\n",
    "    else:\n",
    "        common_vocab[word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1f230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the words by occurrences and create the vocabulary.\n",
    "\n",
    "final_words = [\"< pad >\", \"< unk >\"]\n",
    "for word, count in sorted(common_vocab.items(), key = lambda item: item[1], reverse = True):\n",
    "    final_words.append(word)\n",
    "\n",
    "index = range(0,len(final_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a162e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vocabulary = pd.DataFrame(zip(final_words, index), columns = [\"word\", \"index\"])\n",
    "final_vocabulary.index = final_vocabulary.index + 1  # shifting index\n",
    "final_vocabulary = final_vocabulary.sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba9f1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; pad &gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>Demel</td>\n",
       "      <td>6179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>Kekkila</td>\n",
       "      <td>6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>T&amp;N</td>\n",
       "      <td>6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>Yr</td>\n",
       "      <td>6182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>Lenzing</td>\n",
       "      <td>6183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6184 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  index\n",
       "1     < pad >      0\n",
       "2     < unk >      1\n",
       "3           .      2\n",
       "4           ,      3\n",
       "5         the      4\n",
       "...       ...    ...\n",
       "6180    Demel   6179\n",
       "6181  Kekkila   6180\n",
       "6182      T&N   6181\n",
       "6183       Yr   6182\n",
       "6184  Lenzing   6183\n",
       "\n",
       "[6184 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2381a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'< pad >': [0],\n",
       " '< unk >': [1],\n",
       " '.': [2],\n",
       " ',': [3],\n",
       " 'the': [4],\n",
       " 'of': [5],\n",
       " 'in': [6],\n",
       " 'to': [7],\n",
       " 'a': [8],\n",
       " '(': [9],\n",
       " ')': [10],\n",
       " 'and': [11],\n",
       " '\"': [12],\n",
       " 'on': [13],\n",
       " 'said': [14],\n",
       " \"'s\": [15],\n",
       " 'for': [16],\n",
       " '1': [17],\n",
       " '-': [18],\n",
       " 'The': [19],\n",
       " 'was': [20],\n",
       " '2': [21],\n",
       " '-DOCSTART-': [22],\n",
       " '0': [23],\n",
       " '3': [24],\n",
       " 'at': [25],\n",
       " 'with': [26],\n",
       " 'that': [27],\n",
       " 'from': [28],\n",
       " 'by': [29],\n",
       " 'is': [30],\n",
       " ':': [31],\n",
       " 'as': [32],\n",
       " 'he': [33],\n",
       " '4': [34],\n",
       " 'had': [35],\n",
       " 'has': [36],\n",
       " 'it': [37],\n",
       " 'his': [38],\n",
       " 'not': [39],\n",
       " 'were': [40],\n",
       " 'be': [41],\n",
       " 'an': [42],\n",
       " 'have': [43],\n",
       " 'after': [44],\n",
       " 'who': [45],\n",
       " 'will': [46],\n",
       " '5': [47],\n",
       " 'but': [48],\n",
       " 'first': [49],\n",
       " 'U.S.': [50],\n",
       " 'been': [51],\n",
       " '$': [52],\n",
       " '--': [53],\n",
       " 'two': [54],\n",
       " 'are': [55],\n",
       " 'their': [56],\n",
       " '6': [57],\n",
       " 'beat': [58],\n",
       " 'which': [59],\n",
       " 'would': [60],\n",
       " 'up': [61],\n",
       " 'I': [62],\n",
       " 'its': [63],\n",
       " 'they': [64],\n",
       " 'percent': [65],\n",
       " 'year': [66],\n",
       " 'out': [67],\n",
       " 'Thursday': [68],\n",
       " 'this': [69],\n",
       " 'last': [70],\n",
       " 'million': [71],\n",
       " 'over': [72],\n",
       " 'Wednesday': [73],\n",
       " 'one': [74],\n",
       " '7': [75],\n",
       " 'government': [76],\n",
       " 'against': [77],\n",
       " '/': [78],\n",
       " 'police': [79],\n",
       " 'when': [80],\n",
       " 'second': [81],\n",
       " 'also': [82],\n",
       " 'Tuesday': [83],\n",
       " 'He': [84],\n",
       " 'It': [85],\n",
       " 'A': [86],\n",
       " 'three': [87],\n",
       " 'told': [88],\n",
       " 'new': [89],\n",
       " '10': [90],\n",
       " 'Monday': [91],\n",
       " 'or': [92],\n",
       " 'Friday': [93],\n",
       " 'about': [94],\n",
       " 'people': [95],\n",
       " 'In': [96],\n",
       " 'her': [97],\n",
       " '9': [98],\n",
       " '1996-08-28': [99],\n",
       " 'no': [100],\n",
       " 'we': [101],\n",
       " 'won': [102],\n",
       " 'New': [103],\n",
       " 'into': [104],\n",
       " 'under': [105],\n",
       " 'some': [106],\n",
       " 'Sunday': [107],\n",
       " 'But': [108],\n",
       " '8': [109],\n",
       " 'more': [110],\n",
       " 'before': [111],\n",
       " 'week': [112],\n",
       " \"'\": [113],\n",
       " 'than': [114],\n",
       " 'time': [115],\n",
       " 'Germany': [116],\n",
       " 'could': [117],\n",
       " 'market': [118],\n",
       " 'We': [119],\n",
       " 'points': [120],\n",
       " 'between': [121],\n",
       " 'Australia': [122],\n",
       " 'years': [123],\n",
       " 'Britain': [124],\n",
       " 'since': [125],\n",
       " 'other': [126],\n",
       " 'SOCCER': [127],\n",
       " 'AT': [128],\n",
       " 'all': [129],\n",
       " 'played': [130],\n",
       " 'France': [131],\n",
       " 'state': [132],\n",
       " 'company': [133],\n",
       " 'England': [134],\n",
       " 'Saturday': [135],\n",
       " '1996-08-22': [136],\n",
       " 'only': [137],\n",
       " 'officials': [138],\n",
       " 'group': [139],\n",
       " '1996-08-29': [140],\n",
       " 'there': [141],\n",
       " '1996': [142],\n",
       " 'round': [143],\n",
       " 'Minister': [144],\n",
       " 'South': [145],\n",
       " '11': [146],\n",
       " '1996-08-27': [147],\n",
       " 'off': [148],\n",
       " 'match': [149],\n",
       " '13': [150],\n",
       " 'down': [151],\n",
       " 'six': [152],\n",
       " '6-4': [153],\n",
       " '6-3': [154],\n",
       " 'four': [155],\n",
       " 'because': [156],\n",
       " '21': [157],\n",
       " 'five': [158],\n",
       " '15': [159],\n",
       " 'him': [160],\n",
       " 'Spain': [161],\n",
       " '1996-08-26': [162],\n",
       " 'next': [163],\n",
       " 'President': [164],\n",
       " 'former': [165],\n",
       " 'official': [166],\n",
       " 'United': [167],\n",
       " 'home': [168],\n",
       " 'she': [169],\n",
       " 'do': [170],\n",
       " 'third': [171],\n",
       " 'spokesman': [172],\n",
       " 'expected': [173],\n",
       " 'did': [174],\n",
       " 'day': [175],\n",
       " 'just': [176],\n",
       " 'games': [177],\n",
       " 'through': [178],\n",
       " 'statement': [179],\n",
       " '70': [180],\n",
       " 'win': [181],\n",
       " 'NEW': [182],\n",
       " 'made': [183],\n",
       " '12': [184],\n",
       " '1996-08-23': [185],\n",
       " 'them': [186],\n",
       " '14': [187],\n",
       " 'lost': [188],\n",
       " 'where': [189],\n",
       " '20': [190],\n",
       " '6-2': [191],\n",
       " 'world': [192],\n",
       " 'July': [193],\n",
       " 'Russian': [194],\n",
       " 'September': [195],\n",
       " 'RESULTS': [196],\n",
       " \"n't\": [197],\n",
       " 'if': [198],\n",
       " 'back': [199],\n",
       " 'Italy': [200],\n",
       " 'shares': [201],\n",
       " 'China': [202],\n",
       " 'August': [203],\n",
       " 'YORK': [204],\n",
       " 'president': [205],\n",
       " 'Cup': [206],\n",
       " '2.': [207],\n",
       " '3.': [208],\n",
       " '1.': [209],\n",
       " 'DIVISION': [210],\n",
       " 'British': [211],\n",
       " 'LONDON': [212],\n",
       " 'Clinton': [213],\n",
       " 'any': [214],\n",
       " 'while': [215],\n",
       " 'Japan': [216],\n",
       " 'seconds': [217],\n",
       " 'reported': [218],\n",
       " 'billion': [219],\n",
       " '69': [220],\n",
       " 'matches': [221],\n",
       " 'month': [222],\n",
       " 'team': [223],\n",
       " 'v': [224],\n",
       " 'Russia': [225],\n",
       " 'Pakistan': [226],\n",
       " 'division': [227],\n",
       " 'European': [228],\n",
       " 'meeting': [229],\n",
       " 'London': [230],\n",
       " 'They': [231],\n",
       " 'June': [232],\n",
       " '30': [233],\n",
       " 'being': [234],\n",
       " 'German': [235],\n",
       " 'news': [236],\n",
       " 'added': [237],\n",
       " '71': [238],\n",
       " 'Results': [239],\n",
       " '1996-08-25': [240],\n",
       " 'half': [241],\n",
       " 'At': [242],\n",
       " 'peace': [243],\n",
       " 'still': [244],\n",
       " '1/2': [245],\n",
       " 'metres': [246],\n",
       " 'earlier': [247],\n",
       " 'talks': [248],\n",
       " 'set': [249],\n",
       " 'tonnes': [250],\n",
       " 'killed': [251],\n",
       " 'Sweden': [252],\n",
       " 'now': [253],\n",
       " 'season': [254],\n",
       " 'take': [255],\n",
       " 'held': [256],\n",
       " 'during': [257],\n",
       " 'Reuters': [258],\n",
       " 'should': [259],\n",
       " 'part': [260],\n",
       " 'around': [261],\n",
       " 'India': [262],\n",
       " 'National': [263],\n",
       " 'party': [264],\n",
       " 'elections': [265],\n",
       " 'took': [266],\n",
       " 'Bank': [267],\n",
       " 'game': [268],\n",
       " 'early': [269],\n",
       " 'lead': [270],\n",
       " 'number': [271],\n",
       " 'capital': [272],\n",
       " '68': [273],\n",
       " 'innings': [274],\n",
       " '6-1': [275],\n",
       " 'soccer': [276],\n",
       " 'minutes': [277],\n",
       " 'due': [278],\n",
       " 'end': [279],\n",
       " 'saying': [280],\n",
       " 'days': [281],\n",
       " '7-6': [282],\n",
       " 'b': [283],\n",
       " '100': [284],\n",
       " 'results': [285],\n",
       " 'Open': [286],\n",
       " 'foreign': [287],\n",
       " 'so': [288],\n",
       " 'can': [289],\n",
       " 'political': [290],\n",
       " 'international': [291],\n",
       " 'West': [292],\n",
       " '22': [293],\n",
       " 'per': [294],\n",
       " 'York': [295],\n",
       " 'final': [296],\n",
       " 'Belgium': [297],\n",
       " 'you': [298],\n",
       " 'Newsroom': [299],\n",
       " 'most': [300],\n",
       " 'French': [301],\n",
       " 'victory': [302],\n",
       " 'well': [303],\n",
       " '50': [304],\n",
       " 'Netherlands': [305],\n",
       " 'visit': [306],\n",
       " 'country': [307],\n",
       " 'Iraq': [308],\n",
       " 'seven': [309],\n",
       " '25': [310],\n",
       " 'champion': [311],\n",
       " 'Israel': [312],\n",
       " 'our': [313],\n",
       " 'minute': [314],\n",
       " 'American': [315],\n",
       " 'says': [316],\n",
       " 'left': [317],\n",
       " '66': [318],\n",
       " 'Africa': [319],\n",
       " 'Czech': [320],\n",
       " '1996-08-24': [321],\n",
       " 'league': [322],\n",
       " 'play': [323],\n",
       " 'LEAGUE': [324],\n",
       " '4.': [325],\n",
       " 'profit': [326],\n",
       " '67': [327],\n",
       " 'vs.': [328],\n",
       " '5.': [329],\n",
       " '6.': [330],\n",
       " '1995': [331],\n",
       " '24': [332],\n",
       " 'very': [333],\n",
       " 'leader': [334],\n",
       " '7-5': [335],\n",
       " 'Republic': [336],\n",
       " 'local': [337],\n",
       " 'found': [338],\n",
       " 'war': [339],\n",
       " 'go': [340],\n",
       " 'same': [341],\n",
       " 'support': [342],\n",
       " 'Inc': [343],\n",
       " 'newsroom': [344],\n",
       " 'close': [345],\n",
       " 'run': [346],\n",
       " 'called': [347],\n",
       " 'States': [348],\n",
       " 'meet': [349],\n",
       " 'CHICAGO': [350],\n",
       " 'say': [351],\n",
       " 'World': [352],\n",
       " 'then': [353],\n",
       " 'man': [354],\n",
       " 'what': [355],\n",
       " 'town': [356],\n",
       " 'military': [357],\n",
       " 'lower': [358],\n",
       " 'prices': [359],\n",
       " 'ago': [360],\n",
       " 'singles': [361],\n",
       " 'eight': [362],\n",
       " '64': [363],\n",
       " 'both': [364],\n",
       " 'put': [365],\n",
       " 'Moscow': [366],\n",
       " 'Mark': [367],\n",
       " '72': [368],\n",
       " 'newspaper': [369],\n",
       " 'deal': [370],\n",
       " 'runs': [371],\n",
       " 'bank': [372],\n",
       " 'make': [373],\n",
       " '16': [374],\n",
       " 'trade': [375],\n",
       " 'OF': [376],\n",
       " 'race': [377],\n",
       " 'goals': [378],\n",
       " 'Men': [379],\n",
       " '60': [380],\n",
       " 'St': [381],\n",
       " 'rate': [382],\n",
       " 'cents': [383],\n",
       " 'issue': [384],\n",
       " 'gave': [385],\n",
       " 'pct': [386],\n",
       " 'Prime': [387],\n",
       " 'There': [388],\n",
       " 'months': [389],\n",
       " 'May': [390],\n",
       " 'behind': [391],\n",
       " 'city': [392],\n",
       " 'FIRST': [393],\n",
       " 'good': [394],\n",
       " 'opposition': [395],\n",
       " 'minister': [396],\n",
       " '75': [397],\n",
       " 'Michael': [398],\n",
       " 'Women': [399],\n",
       " 'League': [400],\n",
       " 'ended': [401],\n",
       " 'Hong': [402],\n",
       " 'report': [403],\n",
       " 'leaders': [404],\n",
       " 'rebels': [405],\n",
       " 'Iraqi': [406],\n",
       " 'Dutch': [407],\n",
       " 'tournament': [408],\n",
       " 'until': [409],\n",
       " 'agreed': [410],\n",
       " 'late': [411],\n",
       " 'Australian': [412],\n",
       " 'northern': [413],\n",
       " 'weekend': [414],\n",
       " 'near': [415],\n",
       " 'dollar': [416],\n",
       " 'price': [417],\n",
       " 'net': [418],\n",
       " '74': [419],\n",
       " 'get': [420],\n",
       " '7.': [421],\n",
       " 'plan': [422],\n",
       " 'security': [423],\n",
       " 'Kong': [424],\n",
       " 'going': [425],\n",
       " 'top': [426],\n",
       " 'agency': [427],\n",
       " 'African': [428],\n",
       " 'record': [429],\n",
       " 'players': [430],\n",
       " '73': [431],\n",
       " 'Attendance': [432],\n",
       " ';': [433],\n",
       " 'want': [434],\n",
       " 'start': [435],\n",
       " 'Paul': [436],\n",
       " 'another': [437],\n",
       " 'Sri': [438],\n",
       " 'drawn': [439],\n",
       " 'miles': [440],\n",
       " 'refugees': [441],\n",
       " 'chief': [442],\n",
       " 'John': [443],\n",
       " 'office': [444],\n",
       " 'place': [445],\n",
       " 'David': [446],\n",
       " 'Democratic': [447],\n",
       " 'economic': [448],\n",
       " 'sales': [449],\n",
       " 'taking': [450],\n",
       " 'my': [451],\n",
       " 'CRICKET': [452],\n",
       " 'SAN': [453],\n",
       " '8.': [454],\n",
       " 'court': [455],\n",
       " 'arrested': [456],\n",
       " 'Commission': [457],\n",
       " 'quoted': [458],\n",
       " 'demand': [459],\n",
       " 'Israeli': [460],\n",
       " 'those': [461],\n",
       " 'Party': [462],\n",
       " 'Palestinian': [463],\n",
       " 'Corp': [464],\n",
       " 'GMT': [465],\n",
       " 'Ahmed': [466],\n",
       " 'championship': [467],\n",
       " 'allowed': [468],\n",
       " 'Foreign': [469],\n",
       " 'many': [470],\n",
       " 'IN': [471],\n",
       " 'already': [472],\n",
       " 'women': [473],\n",
       " 'including': [474],\n",
       " 'central': [475],\n",
       " 'several': [476],\n",
       " 'de': [477],\n",
       " 'following': [478],\n",
       " 'television': [479],\n",
       " 'Arafat': [480],\n",
       " 'hit': [481],\n",
       " 'km': [482],\n",
       " 'Martin': [483],\n",
       " '17': [484],\n",
       " '28': [485],\n",
       " 'Yeltsin': [486],\n",
       " 'Union': [487],\n",
       " 'authorities': [488],\n",
       " 'fell': [489],\n",
       " 'later': [490],\n",
       " 'forces': [491],\n",
       " 'southern': [492],\n",
       " 'men': [493],\n",
       " 'ahead': [494],\n",
       " '31': [495],\n",
       " 'may': [496],\n",
       " 'M.': [497],\n",
       " '1-0': [498],\n",
       " '26': [499],\n",
       " 'Dole': [500],\n",
       " 'whether': [501],\n",
       " 'hours': [502],\n",
       " 'came': [503],\n",
       " 'reporters': [504],\n",
       " 'announced': [505],\n",
       " 'work': [506],\n",
       " 'troops': [507],\n",
       " 'election': [508],\n",
       " 'loss': [509],\n",
       " 'weeks': [510],\n",
       " 'way': [511],\n",
       " 'Brazil': [512],\n",
       " '19': [513],\n",
       " '...': [514],\n",
       " 'general': [515],\n",
       " 'return': [516],\n",
       " 'parliament': [517],\n",
       " 'higher': [518],\n",
       " 'closed': [519],\n",
       " '23': [520],\n",
       " 'night': [521],\n",
       " 'Finland': [522],\n",
       " '1994': [523],\n",
       " 'Zealand': [524],\n",
       " 'vs': [525],\n",
       " '18': [526],\n",
       " '65': [527],\n",
       " 'Chicago': [528],\n",
       " 'test': [529],\n",
       " 'This': [530],\n",
       " 'began': [531],\n",
       " 'share': [532],\n",
       " 'power': [533],\n",
       " 'went': [534],\n",
       " 'national': [535],\n",
       " 'decision': [536],\n",
       " 'agreement': [537],\n",
       " 'plans': [538],\n",
       " 'countries': [539],\n",
       " 'English': [540],\n",
       " 'ministry': [541],\n",
       " 'quarter': [542],\n",
       " 'Washington': [543],\n",
       " 'like': [544],\n",
       " 'few': [545],\n",
       " 'asked': [546],\n",
       " '1997': [547],\n",
       " 'oil': [548],\n",
       " 'head': [549],\n",
       " 'away': [550],\n",
       " 'morning': [551],\n",
       " 'north': [552],\n",
       " 'Lebed': [553],\n",
       " 'Police': [554],\n",
       " 'trading': [555],\n",
       " 'taken': [556],\n",
       " 'main': [557],\n",
       " 'fighting': [558],\n",
       " 'leading': [559],\n",
       " 'Austria': [560],\n",
       " 'Sydney': [561],\n",
       " 'Olympic': [562],\n",
       " 'money': [563],\n",
       " 'index': [564],\n",
       " 'such': [565],\n",
       " 'current': [566],\n",
       " 'side': [567],\n",
       " 'U.N.': [568],\n",
       " 'rights': [569],\n",
       " 'past': [570],\n",
       " '63': [571],\n",
       " 'c': [572],\n",
       " 'scored': [573],\n",
       " 'signed': [574],\n",
       " 'Canada': [575],\n",
       " 'STANDINGS': [576],\n",
       " 'hits': [577],\n",
       " 'much': [578],\n",
       " 'major': [579],\n",
       " 'army': [580],\n",
       " 'business': [581],\n",
       " 'budget': [582],\n",
       " 'Europe': [583],\n",
       " 'Ukraine': [584],\n",
       " 'growth': [585],\n",
       " 'East': [586],\n",
       " '40': [587],\n",
       " 'nine': [588],\n",
       " 'area': [589],\n",
       " 'Standings': [590],\n",
       " 'think': [591],\n",
       " 'accused': [592],\n",
       " 'total': [593],\n",
       " 'campaign': [594],\n",
       " 'previous': [595],\n",
       " 'Two': [596],\n",
       " 'region': [597],\n",
       " 'attack': [598],\n",
       " 'own': [599],\n",
       " 'strike': [600],\n",
       " '96': [601],\n",
       " 'draw': [602],\n",
       " 'winning': [603],\n",
       " '62': [604],\n",
       " 'Lanka': [605],\n",
       " 'Co': [606],\n",
       " 'recent': [607],\n",
       " 'On': [608],\n",
       " 'led': [609],\n",
       " 'died': [610],\n",
       " '27': [611],\n",
       " 'hold': [612],\n",
       " 'PCT': [613],\n",
       " 'without': [614],\n",
       " 'working': [615],\n",
       " 'control': [616],\n",
       " 'plane': [617],\n",
       " 'these': [618],\n",
       " 'cash': [619],\n",
       " 'future': [620],\n",
       " 'available': [621],\n",
       " 'club': [622],\n",
       " 'White': [623],\n",
       " 'Akram': [624],\n",
       " 'Ireland': [625],\n",
       " 'best': [626],\n",
       " '9.': [627],\n",
       " 'high': [628],\n",
       " 'seen': [629],\n",
       " 'vote': [630],\n",
       " 'again': [631],\n",
       " '---': [632],\n",
       " 'ban': [633],\n",
       " 'might': [634],\n",
       " 'March': [635],\n",
       " 'right': [636],\n",
       " 'sent': [637],\n",
       " 'ceasefire': [638],\n",
       " 'failed': [639],\n",
       " 'help': [640],\n",
       " 'does': [641],\n",
       " 'give': [642],\n",
       " 'Paris': [643],\n",
       " 'fourth': [644],\n",
       " 'little': [645],\n",
       " 'wickets': [646],\n",
       " 'released': [647],\n",
       " 'tour': [648],\n",
       " 'case': [649],\n",
       " 'conference': [650],\n",
       " \"'re\": [651],\n",
       " 'Dutroux': [652],\n",
       " 'disease': [653],\n",
       " 'long': [654],\n",
       " 'period': [655],\n",
       " 'manager': [656],\n",
       " 'me': [657],\n",
       " 'No': [658],\n",
       " 'embassy': [659],\n",
       " 'An': [660],\n",
       " 'prime': [661],\n",
       " 'average': [662],\n",
       " 'started': [663],\n",
       " 'champions': [664],\n",
       " 'cut': [665],\n",
       " 'City': [666],\n",
       " 'overs': [667],\n",
       " '29': [668],\n",
       " 'least': [669],\n",
       " 'us': [670],\n",
       " 'Italian': [671],\n",
       " 'across': [672],\n",
       " 'Aug': [673],\n",
       " 'Kurdish': [674],\n",
       " 'free': [675],\n",
       " 'planned': [676],\n",
       " 'October': [677],\n",
       " 'stories': [678],\n",
       " 'members': [679],\n",
       " 'tennis': [680],\n",
       " '59': [681],\n",
       " 'Wasim': [682],\n",
       " 'Thomas': [683],\n",
       " 'Costa': [684],\n",
       " 'Ajax': [685],\n",
       " 'Leading': [686],\n",
       " 'order': [687],\n",
       " 'service': [688],\n",
       " 'Chechnya': [689],\n",
       " 'production': [690],\n",
       " 'airport': [691],\n",
       " 'public': [692],\n",
       " 'Ministry': [693],\n",
       " 'rose': [694],\n",
       " 'Jordan': [695],\n",
       " 'press': [696],\n",
       " 'strong': [697],\n",
       " 'April': [698],\n",
       " 'given': [699],\n",
       " 'Romania': [700],\n",
       " 'short': [701],\n",
       " 'Slovakia': [702],\n",
       " '54': [703],\n",
       " 'BASEBALL': [704],\n",
       " 'shot': [705],\n",
       " '10.': [706],\n",
       " 'declared': [707],\n",
       " 'children': [708],\n",
       " 'yet': [709],\n",
       " 'Bosnia': [710],\n",
       " 'Bosnian': [711],\n",
       " 'San': [712],\n",
       " 'Republican': [713],\n",
       " 'bonds': [714],\n",
       " 'further': [715],\n",
       " 'reports': [716],\n",
       " 'State': [717],\n",
       " 'must': [718],\n",
       " 'trying': [719],\n",
       " 'possible': [720],\n",
       " 'markets': [721],\n",
       " 'interest': [722],\n",
       " 'Amsterdam': [723],\n",
       " 'If': [724],\n",
       " 'A.': [725],\n",
       " 'hospital': [726],\n",
       " 'standings': [727],\n",
       " 'tabulate': [728],\n",
       " 'CITY': [729],\n",
       " 'seed': [730],\n",
       " 'Moslem': [731],\n",
       " 'stock': [732],\n",
       " 'Jerusalem': [733],\n",
       " 'Peter': [734],\n",
       " 'known': [735],\n",
       " 'brought': [736],\n",
       " 'used': [737],\n",
       " 'Taiwan': [738],\n",
       " 'opening': [739],\n",
       " 'term': [740],\n",
       " 'face': [741],\n",
       " 'received': [742],\n",
       " 'Poland': [743],\n",
       " 'guerrillas': [744],\n",
       " 'rates': [745],\n",
       " 'forced': [746],\n",
       " 'law': [747],\n",
       " 'industry': [748],\n",
       " 'TENNIS': [749],\n",
       " '2-0': [750],\n",
       " 'coach': [751],\n",
       " 'series': [752],\n",
       " 'fifth': [753],\n",
       " 'Robert': [754],\n",
       " 'woman': [755],\n",
       " 'come': [756],\n",
       " 'clear': [757],\n",
       " 'death': [758],\n",
       " 'charges': [759],\n",
       " 'She': [760],\n",
       " 'Ltd': [761],\n",
       " 'Kenya': [762],\n",
       " 'Nigeria': [763],\n",
       " 'call': [764],\n",
       " 'details': [765],\n",
       " 'despite': [766],\n",
       " 'estimated': [767],\n",
       " 'Turkey': [768],\n",
       " 'That': [769],\n",
       " 'likely': [770],\n",
       " 'immediately': [771],\n",
       " 'PARIS': [772],\n",
       " 'date': [773],\n",
       " 'squad': [774],\n",
       " \"'S\": [775],\n",
       " 'Argentina': [776],\n",
       " '1,000': [777],\n",
       " 'injured': [778],\n",
       " '*': [779],\n",
       " 'companies': [780],\n",
       " 'point': [781],\n",
       " 'old': [782],\n",
       " 'showed': [783],\n",
       " 'passengers': [784],\n",
       " 'small': [785],\n",
       " 'private': [786],\n",
       " 'yen': [787],\n",
       " 'train': [788],\n",
       " '48': [789],\n",
       " 'action': [790],\n",
       " 'human': [791],\n",
       " 'contract': [792],\n",
       " 'figures': [793],\n",
       " 'Egypt': [794],\n",
       " 'North': [795],\n",
       " 'Iran': [796],\n",
       " 'level': [797],\n",
       " '76': [798],\n",
       " 'daily': [799],\n",
       " 'use': [800],\n",
       " 'result': [801],\n",
       " 'better': [802],\n",
       " 'California': [803],\n",
       " 'named': [804],\n",
       " '0-0': [805],\n",
       " 'captain': [806],\n",
       " 'Wimbledon': [807],\n",
       " 'L': [808],\n",
       " '61': [809],\n",
       " 'got': [810],\n",
       " 'each': [811],\n",
       " 'One': [812],\n",
       " 'groups': [813],\n",
       " 'latest': [814],\n",
       " 'Nations': [815],\n",
       " 'trip': [816],\n",
       " 'forecast': [817],\n",
       " 'process': [818],\n",
       " 'Japanese': [819],\n",
       " 'policy': [820],\n",
       " 'workers': [821],\n",
       " 'see': [822],\n",
       " 'believed': [823],\n",
       " 'how': [824],\n",
       " 'sold': [825],\n",
       " 'force': [826],\n",
       " 'analysts': [827],\n",
       " 'financial': [828],\n",
       " 'earnings': [829],\n",
       " 'exports': [830],\n",
       " 'unless': [831],\n",
       " 'halftime': [832],\n",
       " 'seeding': [833],\n",
       " 'holiday': [834],\n",
       " 'Waqar': [835],\n",
       " 'Younis': [836],\n",
       " 'Mushtaq': [837],\n",
       " 'Croft': [838],\n",
       " 'TORONTO': [839],\n",
       " 'BALTIMORE': [840],\n",
       " 'PSV': [841],\n",
       " 'Belgian': [842],\n",
       " 'pay': [843],\n",
       " 'soon': [844],\n",
       " 'prison': [845],\n",
       " 'rise': [846],\n",
       " 'Atlanta': [847],\n",
       " 'Serb': [848],\n",
       " '6-0': [849],\n",
       " 'chairman': [850],\n",
       " 'nearly': [851],\n",
       " 'TO': [852],\n",
       " 'International': [853],\n",
       " 'coming': [854],\n",
       " 'today': [855],\n",
       " 'border': [856],\n",
       " 'scheduled': [857],\n",
       " 'Total': [858],\n",
       " 'title': [859],\n",
       " 'S.': [860],\n",
       " 'rule': [861],\n",
       " 'within': [862],\n",
       " 'straight': [863],\n",
       " 'making': [864],\n",
       " 'violence': [865],\n",
       " 'road': [866],\n",
       " 'levels': [867],\n",
       " 'times': [868],\n",
       " 'playing': [869],\n",
       " 'confirmed': [870],\n",
       " '56': [871],\n",
       " 'Security': [872],\n",
       " 'convention': [873],\n",
       " 'Exchange': [874],\n",
       " 'pound': [875],\n",
       " 'buy': [876],\n",
       " 'senior': [877],\n",
       " 'message': [878],\n",
       " 'met': [879],\n",
       " 'Saudi': [880],\n",
       " 'Net': [881],\n",
       " 'keep': [882],\n",
       " '53': [883],\n",
       " 'AMSTERDAM': [884],\n",
       " 'know': [885],\n",
       " 'Khan': [886],\n",
       " 'Mullally': [887],\n",
       " 'OPEN': [888],\n",
       " 'Switzerland': [889],\n",
       " 'homer': [890],\n",
       " 'inning': [891],\n",
       " 'tried': [892],\n",
       " 'Central': [893],\n",
       " 'Halftime': [894],\n",
       " 'south': [895],\n",
       " 'Bill': [896],\n",
       " 'Grand': [897],\n",
       " '55': [898],\n",
       " 'completed': [899],\n",
       " 'charged': [900],\n",
       " 'illegal': [901],\n",
       " 'nuclear': [902],\n",
       " 'position': [903],\n",
       " 'independence': [904],\n",
       " 'Indian': [905],\n",
       " 'First': [906],\n",
       " 'gold': [907],\n",
       " 'reached': [908],\n",
       " 'struck': [909],\n",
       " 'services': [910],\n",
       " 'comment': [911],\n",
       " 'health': [912],\n",
       " 'conditions': [913],\n",
       " 'Chinese': [914],\n",
       " 'island': [915],\n",
       " 'Association': [916],\n",
       " 'FOR': [917],\n",
       " 'here': [918],\n",
       " 'Netanyahu': [919],\n",
       " 'full': [920],\n",
       " 'kept': [921],\n",
       " 'based': [922],\n",
       " 'rebel': [923],\n",
       " 'continue': [924],\n",
       " 'areas': [925],\n",
       " 'outside': [926],\n",
       " 'PUK': [927],\n",
       " 'parties': [928],\n",
       " 'attacks': [929],\n",
       " 'problem': [930],\n",
       " '45': [931],\n",
       " 'After': [932],\n",
       " 'course': [933],\n",
       " '2-1': [934],\n",
       " '1-1': [935],\n",
       " 'aggregate': [936],\n",
       " 'prefix': [937],\n",
       " 'opened': [938],\n",
       " 'tie': [939],\n",
       " 'percentage': [940],\n",
       " '58': [941],\n",
       " 'ground': [942],\n",
       " 'even': [943],\n",
       " 'able': [944],\n",
       " 'arrived': [945],\n",
       " \"'m\": [946],\n",
       " 'civil': [947],\n",
       " 'letter': [948],\n",
       " 'Grozny': [949],\n",
       " 'poor': [950],\n",
       " 'centre': [951],\n",
       " 'wife': [952],\n",
       " 'sell': [953],\n",
       " 'Mexico': [954],\n",
       " 'OSCE': [955],\n",
       " 'change': [956],\n",
       " 'Group': [957],\n",
       " 'wheat': [958],\n",
       " 'EU': [959],\n",
       " 'needed': [960],\n",
       " 'denied': [961],\n",
       " 'radio': [962],\n",
       " 'paper': [963],\n",
       " 'goal': [964],\n",
       " 'bond': [965],\n",
       " '300': [966],\n",
       " 'source': [967],\n",
       " 'flight': [968],\n",
       " 'PRESS': [969],\n",
       " 'DIGEST': [970],\n",
       " 'Turkish': [971],\n",
       " 'step': [972],\n",
       " '42': [973],\n",
       " 'according': [974],\n",
       " 'too': [975],\n",
       " '77': [976],\n",
       " 'leg': [977],\n",
       " 'winner': [978],\n",
       " 'Result': [979],\n",
       " 'denotes': [980],\n",
       " 'director': [981],\n",
       " 'great': [982],\n",
       " 'penalty': [983],\n",
       " 'Johnson': [984],\n",
       " 'BOSTON': [985],\n",
       " 'FRANCISCO': [986],\n",
       " 'big': [987],\n",
       " 'Williams': [988],\n",
       " 'system': [989],\n",
       " 'break': [990],\n",
       " 'village': [991],\n",
       " 'returned': [992],\n",
       " 'himself': [993],\n",
       " 'less': [994],\n",
       " 'stage': [995],\n",
       " 'treaty': [996],\n",
       " 'leave': [997],\n",
       " 'House': [998],\n",
       " 'economy': [999],\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vocabulary_dictionary = final_vocabulary[[\"word\",\"index\"]].set_index(\"word\").T.to_dict(\"list\")\n",
    "final_vocabulary_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b20ca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6184"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(final_vocabulary_dictionary)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "827e0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict = dict()\n",
    "tags = list(train_data[\"tag\"].unique())\n",
    "for i, tag in enumerate(tags):\n",
    "    tags_dict[tag] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a55bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-ORG': 1,\n",
       " 'O': 2,\n",
       " 'B-MISC': 3,\n",
       " 'B-PER': 4,\n",
       " 'I-PER': 5,\n",
       " 'B-LOC': 6,\n",
       " 'I-ORG': 7,\n",
       " 'I-MISC': 8,\n",
       " 'I-LOC': 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27be2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = []\n",
    "for tag in train_tags:\n",
    "    new_tags.append(tags_dict[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d82f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_new_tags = []\n",
    "for tag in dev_tags:\n",
    "    dev_new_tags.append(tags_dict[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea37086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map word to index (train)\n",
    "# Unknown word = 1\n",
    "# Else, map to dictionary\n",
    "word_indexes = []\n",
    "true_ners = []\n",
    "sentence = []\n",
    "temp_ner = []\n",
    "for i in range(0, len(train_words)):\n",
    "    ner = new_tags[i]\n",
    "    try:\n",
    "        word = final_vocabulary_dictionary[train_words[i]][0]\n",
    "        \n",
    "    except:\n",
    "        word = 1\n",
    "\n",
    "    if i == len(train_words) - 1:\n",
    "        temp_ner.append(ner)\n",
    "        true_ners.append(temp_ner)\n",
    "        sentence.append(word)\n",
    "        word_indexes.append(sentence)\n",
    "        break\n",
    "\n",
    "    sentence.append(word)\n",
    "    temp_ner.append(ner)\n",
    "    if train_indexes[i+1] == \"1\":\n",
    "        word_indexes.append(sentence)\n",
    "        true_ners.append(temp_ner)\n",
    "        sentence = []\n",
    "        temp_ner = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8bb4fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[959, 1, 235, 764, 7, 4149, 211, 1, 2],\n",
       " [734, 2070],\n",
       " [1381, 136],\n",
       " [19,\n",
       "  228,\n",
       "  457,\n",
       "  14,\n",
       "  13,\n",
       "  68,\n",
       "  37,\n",
       "  1,\n",
       "  26,\n",
       "  235,\n",
       "  4150,\n",
       "  7,\n",
       "  2478,\n",
       "  7,\n",
       "  1,\n",
       "  211,\n",
       "  1,\n",
       "  409,\n",
       "  3544,\n",
       "  2071,\n",
       "  501,\n",
       "  1791,\n",
       "  1922,\n",
       "  653,\n",
       "  289,\n",
       "  41,\n",
       "  1,\n",
       "  7,\n",
       "  1923,\n",
       "  2],\n",
       " [116,\n",
       "  15,\n",
       "  3112,\n",
       "  7,\n",
       "  4,\n",
       "  228,\n",
       "  487,\n",
       "  15,\n",
       "  2752,\n",
       "  1060,\n",
       "  1,\n",
       "  1,\n",
       "  14,\n",
       "  13,\n",
       "  73,\n",
       "  2478,\n",
       "  259,\n",
       "  876,\n",
       "  1,\n",
       "  28,\n",
       "  539,\n",
       "  126,\n",
       "  114,\n",
       "  124,\n",
       "  409,\n",
       "  4,\n",
       "  2479,\n",
       "  4150,\n",
       "  20,\n",
       "  1,\n",
       "  2],\n",
       " [12,\n",
       "  119,\n",
       "  170,\n",
       "  197,\n",
       "  342,\n",
       "  214,\n",
       "  565,\n",
       "  1,\n",
       "  156,\n",
       "  101,\n",
       "  170,\n",
       "  197,\n",
       "  822,\n",
       "  214,\n",
       "  3545,\n",
       "  16,\n",
       "  37,\n",
       "  3,\n",
       "  12,\n",
       "  4,\n",
       "  457,\n",
       "  15,\n",
       "  442,\n",
       "  172,\n",
       "  1,\n",
       "  1297,\n",
       "  2480,\n",
       "  1,\n",
       "  88,\n",
       "  8,\n",
       "  236,\n",
       "  3546,\n",
       "  2],\n",
       " [84,\n",
       "  14,\n",
       "  715,\n",
       "  2479,\n",
       "  2256,\n",
       "  20,\n",
       "  2753,\n",
       "  11,\n",
       "  198,\n",
       "  37,\n",
       "  20,\n",
       "  338,\n",
       "  27,\n",
       "  790,\n",
       "  20,\n",
       "  960,\n",
       "  37,\n",
       "  259,\n",
       "  41,\n",
       "  556,\n",
       "  29,\n",
       "  4,\n",
       "  228,\n",
       "  487,\n",
       "  2],\n",
       " [84,\n",
       "  14,\n",
       "  8,\n",
       "  2257,\n",
       "  70,\n",
       "  222,\n",
       "  29,\n",
       "  959,\n",
       "  1,\n",
       "  3113,\n",
       "  4916,\n",
       "  3547,\n",
       "  7,\n",
       "  633,\n",
       "  1923,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  11,\n",
       "  4151,\n",
       "  1,\n",
       "  28,\n",
       "  4,\n",
       "  791,\n",
       "  11,\n",
       "  2754,\n",
       "  1112,\n",
       "  3548,\n",
       "  20,\n",
       "  8,\n",
       "  3549,\n",
       "  3114,\n",
       "  11,\n",
       "  1,\n",
       "  1298,\n",
       "  7,\n",
       "  4917,\n",
       "  791,\n",
       "  912,\n",
       "  2],\n",
       " [3547,\n",
       "  1567,\n",
       "  1,\n",
       "  1477,\n",
       "  44,\n",
       "  716,\n",
       "  28,\n",
       "  124,\n",
       "  11,\n",
       "  131,\n",
       "  27,\n",
       "  105,\n",
       "  1,\n",
       "  913,\n",
       "  1923,\n",
       "  117,\n",
       "  792,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  9,\n",
       "  2072,\n",
       "  10,\n",
       "  53,\n",
       "  1791,\n",
       "  1922,\n",
       "  653,\n",
       "  2],\n",
       " [108,\n",
       "  3547,\n",
       "  410,\n",
       "  7,\n",
       "  3115,\n",
       "  38,\n",
       "  2257,\n",
       "  44,\n",
       "  4,\n",
       "  959,\n",
       "  15,\n",
       "  2481,\n",
       "  2752,\n",
       "  1060,\n",
       "  3,\n",
       "  1,\n",
       "  2754,\n",
       "  912,\n",
       "  138,\n",
       "  3,\n",
       "  1924,\n",
       "  198,\n",
       "  565,\n",
       "  790,\n",
       "  20,\n",
       "  4918,\n",
       "  32,\n",
       "  141,\n",
       "  20,\n",
       "  137,\n",
       "  8,\n",
       "  3550,\n",
       "  1221,\n",
       "  7,\n",
       "  791,\n",
       "  912,\n",
       "  2]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indexes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc9ad871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map word to index (dev)\n",
    "dev_word_indexes = []\n",
    "dev_true_ners = []\n",
    "sentence = []\n",
    "temp_ner = []\n",
    "for i in range(0, len(dev_words)):\n",
    "    ner = dev_new_tags[i]\n",
    "    try:\n",
    "        word = final_vocabulary_dictionary[dev_words[i]][0]\n",
    "        \n",
    "    except:\n",
    "        word = 1\n",
    "\n",
    "    if i == len(dev_words) - 1:\n",
    "        temp_ner.append(ner)\n",
    "        dev_true_ners.append(temp_ner)\n",
    "        sentence.append(word)\n",
    "        dev_word_indexes.append(sentence)\n",
    "        break\n",
    "        \n",
    "    sentence.append(word)\n",
    "    temp_ner.append(ner)\n",
    "    if train_indexes[i+1] == \"1\":\n",
    "        dev_word_indexes.append(sentence)\n",
    "        dev_true_ners.append(temp_ner)\n",
    "        sentence = []\n",
    "        temp_ner = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2db425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare datasets.\n",
    "\n",
    "class PrepareDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, word_index, label, transform=None):\n",
    "        self.features = word_index\n",
    "        self.labels = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return torch.LongTensor(feature), torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc79ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    length = [len(seq) for seq in sequences]\n",
    "    padded_seq = torch.zeros(len(sequences), max(length)).long()\n",
    "    label_seq = torch.zeros(len(sequences), max(length)).long()\n",
    "    for i, seq in enumerate(zip(sequences, labels)):\n",
    "        end = length[i]\n",
    "        padded_seq[i,:end] = seq[0]\n",
    "        label_seq[i,:end] = seq[1]\n",
    "        \n",
    "    return padded_seq, label_seq, torch.tensor([length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2da83981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train - val\n",
    "train_word_indexes = word_indexes[:11200]\n",
    "train_word_ners = true_ners[:11200]\n",
    "val_word_indexes = word_indexes[11200:]\n",
    "val_word_ners = true_ners[11200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bc13e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets.\n",
    "\n",
    "train_data_lstm = PrepareDataset(train_word_indexes, train_word_ners)\n",
    "val_data_lstm = PrepareDataset(val_word_indexes, val_word_ners)\n",
    "dev_data_lstm = PrepareDataset(dev_word_indexes, dev_true_ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d6c9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader_lstm = torch.utils.data.DataLoader(train_data_lstm, batch_size = batch_size, collate_fn = collate_fn)\n",
    "val_loader_lstm = torch.utils.data.DataLoader(val_data_lstm, batch_size = batch_size, collate_fn = collate_fn)\n",
    "dev_loader_lstm = torch.utils.data.DataLoader(dev_data_lstm, batch_size = batch_size, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d703b3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40]) torch.Size([40])\n",
      "tensor([ 959,    1,  235,  764,    7, 4149,  211,    1,    2,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0]) tensor([1, 2, 3, 2, 2, 2, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# First sentence, padded with 0, has length 40\n",
    "for data,target,_ in train_loader_lstm:\n",
    "    print(data[0].shape, target[0].shape)\n",
    "    print(data[0], target[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39ae6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM architecture.\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, dropout_p):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 100, padding_idx = 0)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "        self.dropout = nn.Dropout(p = dropout_p)\n",
    "        self.elu = nn.ELU()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim // 2, n_layers, batch_first=True, bidirectional=True)   \n",
    "    \n",
    "#         self.fc = nn.Linear(output_size, 10)\n",
    "        self.fc = nn.Linear(output_size, 9)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        cell = self.init_cell(batch_size)\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "#         out, hidden = self.lstm(x, (hidden, cell))\n",
    "        out, hidden = self.lstm(x)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = self.elu(self.linear(out))\n",
    "        out = self.fc(out)\n",
    "        out = out.view(out.shape[0] * out.shape[1], -1)[:,-1]\n",
    "        \n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # 2 x 20 x 128\n",
    "        hidden = torch.zeros(2, batch_size, self.hidden_dim // 2)\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "    def init_cell(self, batch_size):\n",
    "        cell = torch.zeros(2, batch_size, self.hidden_dim // 2)\n",
    "        \n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "129da16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LSTM(100, 128, 256, 1, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d340ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = [0,1,0.7,1,1,1,1,1,1,1]\n",
    "weights = [1,0.7,1,1,1,1,1,1,1]\n",
    "\n",
    "weight_tensor = torch.FloatTensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc20d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-01.\n"
     ]
    }
   ],
   "source": [
    "# Initialize loss function and optimizer.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 0, weight = weight_tensor)\n",
    "\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr = 0.5)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose = True)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.9, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d91576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640])\n",
      "torch.Size([16, 40])\n",
      "tensor([-7.4302e-02,  2.2492e-03, -5.0630e-02, -1.5394e-02,  5.4972e-02,\n",
      "        -9.4638e-03, -3.0981e-02,  6.5776e-02,  4.9027e-02,  2.1473e-02,\n",
      "         1.6051e-02, -8.0813e-03, -9.1731e-03,  9.2439e-03,  4.1248e-03,\n",
      "        -8.9288e-03,  1.1795e-02,  1.4176e-02, -2.2808e-04, -6.2785e-04,\n",
      "         7.6839e-03,  1.7267e-02,  1.0683e-02, -5.1633e-03,  9.8800e-03,\n",
      "         1.8193e-02, -3.5734e-03,  1.0928e-02,  2.3503e-03,  1.1179e-02,\n",
      "        -1.4687e-03,  2.4723e-03,  6.3117e-03,  1.8562e-02,  5.0056e-03,\n",
      "        -2.8291e-03,  1.2038e-02, -5.0723e-03, -3.2683e-03,  6.6601e-03,\n",
      "         9.5724e-03,  3.4080e-03,  6.1816e-03,  8.1863e-04,  6.5112e-04,\n",
      "        -1.6210e-03,  1.6366e-02,  5.5235e-03,  9.6755e-03,  8.8363e-03,\n",
      "         1.0967e-02,  2.6648e-03, -8.8835e-03,  1.3977e-02,  2.0223e-03,\n",
      "         1.5907e-03,  1.5590e-02,  1.2826e-02,  1.1099e-02,  7.7913e-04,\n",
      "         1.2449e-02,  5.5221e-03,  1.1144e-02,  7.0263e-03,  2.8291e-03,\n",
      "         9.5626e-03,  1.4966e-03,  9.3941e-03,  1.0127e-02,  1.6986e-02,\n",
      "         1.7114e-02,  1.0528e-02,  1.4633e-02,  6.6190e-03,  4.6050e-03,\n",
      "         2.7575e-03, -6.0328e-04,  8.0540e-03,  7.2277e-03,  9.7353e-03,\n",
      "        -1.0676e-01, -8.2730e-02, -8.4335e-03,  1.1690e-02,  1.8582e-03,\n",
      "         1.7956e-03,  7.7787e-03,  3.3620e-03,  8.9101e-03,  8.8850e-03,\n",
      "        -1.1667e-02,  1.3965e-02, -4.7754e-03,  6.0138e-03,  1.7429e-03,\n",
      "         4.2104e-03,  1.2021e-02,  2.1123e-02, -7.2021e-04,  4.7440e-03,\n",
      "         1.9688e-03,  2.1207e-02, -4.8797e-03, -1.2165e-02,  6.1261e-03,\n",
      "        -5.1986e-03,  1.6483e-02,  1.9220e-02,  2.0816e-02,  1.9729e-02,\n",
      "         1.8955e-02,  1.5451e-02, -3.2889e-04,  1.6570e-03,  1.3884e-03,\n",
      "         8.8057e-03,  1.1037e-02,  3.6032e-03, -1.0930e-02, -8.6448e-03,\n",
      "         2.5244e-02, -3.3661e-02,  2.2462e-02, -2.0126e-02,  3.6684e-02,\n",
      "        -4.3934e-02, -3.5105e-02, -2.3869e-02,  2.8462e-02,  5.6045e-03,\n",
      "         1.8772e-03, -2.8797e-02,  3.2041e-03, -7.4219e-03,  1.5916e-02,\n",
      "         6.9886e-02,  1.6085e-02,  1.0330e-01,  2.6874e-02, -2.4738e-02,\n",
      "         5.0394e-02,  8.5896e-02,  5.0407e-02,  2.0611e-02, -4.5862e-02,\n",
      "        -9.3289e-02, -7.8965e-02, -2.9508e-03, -1.0613e-01, -6.7013e-02,\n",
      "        -2.6360e-02, -1.2356e-02, -3.1443e-03,  5.3225e-03,  3.8341e-03,\n",
      "         1.0892e-02,  3.7626e-03, -1.5794e-03,  1.2042e-02,  8.8674e-03,\n",
      "         4.9255e-02,  4.5823e-02,  7.9853e-02,  4.4687e-02,  2.1695e-02,\n",
      "         5.0579e-02,  9.6707e-02,  4.2898e-02,  8.4345e-02,  1.7354e-02,\n",
      "        -1.4763e-02,  4.8645e-02,  3.8722e-02,  8.0571e-02, -1.5734e-02,\n",
      "         5.8493e-02,  8.8055e-02, -5.8835e-02,  1.2373e-02,  3.6781e-02,\n",
      "         5.4949e-02, -2.5477e-03,  5.6986e-02,  7.4113e-02, -1.1569e-03,\n",
      "        -1.8888e-02,  1.1349e-01,  2.4089e-02,  4.8707e-03, -1.3989e-02,\n",
      "         8.4295e-02,  3.8232e-03,  1.6919e-02, -1.2155e-03,  5.7205e-03,\n",
      "         1.6887e-02, -1.2801e-03,  4.7345e-03, -6.8417e-03,  2.6795e-03,\n",
      "        -1.3977e-02,  1.5224e-02, -1.2041e-02,  8.9082e-02,  2.4264e-02,\n",
      "         6.4053e-02,  4.0484e-02, -1.4124e-02,  1.6688e-02,  5.2159e-02,\n",
      "        -2.7998e-03,  9.3443e-03, -4.6481e-02, -3.6359e-03,  3.4409e-02,\n",
      "        -6.8265e-02,  1.2459e-02,  3.7298e-02,  2.8220e-02,  1.4391e-02,\n",
      "         2.5898e-02,  8.0911e-02,  5.0951e-02,  1.0462e-02,  6.3121e-02,\n",
      "         1.0754e-02, -1.9056e-02, -6.6477e-02,  6.2593e-02, -3.8163e-02,\n",
      "        -3.1452e-02,  5.9593e-02,  7.1445e-03, -3.2698e-03,  1.5011e-02,\n",
      "        -9.5733e-03, -9.7794e-03, -2.2208e-03, -4.8860e-03, -4.4540e-03,\n",
      "        -2.5583e-02,  6.4507e-02,  3.1753e-02,  3.9830e-02, -5.7352e-04,\n",
      "         6.4778e-02,  4.9908e-02, -1.4738e-02, -1.0264e-02,  1.2240e-01,\n",
      "         5.4201e-02,  3.3622e-02, -7.3754e-02, -7.7924e-03, -2.4105e-03,\n",
      "         6.4843e-03, -2.9983e-02,  7.9664e-02,  1.0857e-02,  2.9883e-03,\n",
      "        -6.4480e-02,  2.3255e-02,  2.1889e-02,  1.1675e-02, -5.0106e-03,\n",
      "         3.0978e-02,  9.4353e-03,  5.7633e-03, -7.8707e-05,  2.2440e-02,\n",
      "         9.4709e-03,  9.1989e-03, -4.5851e-03,  1.8075e-02,  3.0952e-03,\n",
      "         9.0131e-05, -6.7618e-03, -4.3541e-03,  1.6713e-03, -4.8623e-03,\n",
      "        -5.4919e-02, -2.6216e-02, -1.8625e-02, -4.9846e-02, -4.3252e-03,\n",
      "        -1.2786e-01, -7.4234e-02, -1.6457e-02, -6.0963e-02, -2.6314e-02,\n",
      "         3.8854e-02,  1.3691e-01,  1.0463e-02, -3.3600e-02, -1.9599e-02,\n",
      "         1.7897e-02, -6.6326e-02,  6.2531e-02,  3.1581e-02,  9.2144e-02,\n",
      "        -6.0903e-02,  4.3436e-02,  8.8973e-04, -1.2195e-02,  3.3623e-02,\n",
      "         1.5966e-02,  1.3448e-02,  9.2168e-02,  3.0141e-02,  7.0780e-02,\n",
      "        -6.2979e-03,  1.1675e-02,  3.3973e-02, -7.8560e-02,  4.5287e-03,\n",
      "        -2.1208e-02, -6.9772e-02,  1.1457e-02,  6.6470e-02,  2.6662e-02,\n",
      "         1.0745e-01, -2.9639e-02, -2.9895e-02,  2.0877e-02,  3.5499e-02,\n",
      "         5.1585e-02,  4.5789e-02, -6.1351e-03, -2.6415e-03, -5.0056e-02,\n",
      "        -6.3173e-02, -7.6714e-02, -1.0770e-01, -3.8671e-02, -7.2449e-02,\n",
      "        -3.8676e-02, -6.6280e-02, -2.3134e-02,  3.5304e-02,  5.8616e-02,\n",
      "         2.4622e-02,  4.5416e-02,  7.0276e-02,  9.4456e-02,  2.6909e-02,\n",
      "         6.3100e-02,  2.4914e-02,  4.9970e-02,  5.1768e-03,  2.1497e-03,\n",
      "        -1.2625e-03,  8.2365e-04, -4.0354e-03,  4.1452e-03, -6.1758e-03,\n",
      "         7.2169e-03,  3.9686e-03,  1.8001e-03,  8.4816e-03,  8.1011e-04,\n",
      "         1.0040e-02,  5.2738e-02,  3.0578e-03, -4.6099e-03, -5.3122e-02,\n",
      "        -5.6000e-02, -3.8422e-02,  1.3704e-02,  1.8979e-02, -5.0903e-02,\n",
      "         3.2134e-02, -1.0110e-02,  4.0180e-02,  2.7177e-02, -1.6274e-02,\n",
      "         1.8239e-02, -1.5609e-03, -1.2911e-02,  2.3286e-02,  2.7698e-02,\n",
      "         1.6694e-02, -2.6558e-02, -2.2486e-02,  3.3354e-02,  2.9125e-02,\n",
      "         6.3374e-02,  4.3274e-03,  4.0468e-03,  7.6081e-02,  5.7031e-02,\n",
      "         5.9890e-02, -5.6959e-02,  8.8387e-03, -8.6952e-05, -5.6438e-02,\n",
      "        -2.8882e-03, -1.0245e-04, -7.6630e-03,  1.8492e-03,  2.6939e-03,\n",
      "        -4.7690e-02,  3.3870e-02, -4.9704e-02, -3.2765e-02,  3.0364e-02,\n",
      "        -3.0965e-02, -2.1641e-02,  6.9333e-02,  3.8573e-02,  3.5844e-02,\n",
      "        -6.1371e-02, -4.8246e-02, -3.2413e-02,  2.4205e-02, -2.1111e-02,\n",
      "         1.2146e-02,  1.8253e-02, -4.7904e-02, -7.6235e-03,  8.9039e-03,\n",
      "        -3.7988e-02,  1.0620e-02,  3.8296e-02, -7.3301e-02, -3.2098e-02,\n",
      "         3.3676e-02,  1.9064e-02, -3.9607e-02, -1.9132e-02, -1.8725e-03,\n",
      "         1.8457e-02,  1.0601e-03,  1.4175e-02,  9.0341e-03,  2.2521e-02,\n",
      "         1.2758e-02,  8.8825e-03,  9.2310e-03,  8.3490e-03, -5.5541e-03,\n",
      "         1.4656e-02,  2.2423e-02,  2.0466e-02,  8.0334e-05,  1.6971e-02,\n",
      "         3.7865e-03,  4.2388e-03,  7.4735e-03,  3.6569e-03,  2.1950e-04,\n",
      "         1.3721e-03,  6.9544e-03,  3.7471e-03,  2.0875e-03, -2.8092e-03,\n",
      "         6.9126e-03,  3.2459e-03,  1.1300e-02,  7.0522e-03,  6.3046e-03,\n",
      "         5.0899e-03,  3.8332e-03,  1.3959e-02,  9.0645e-03,  3.1486e-03,\n",
      "         1.2880e-02,  1.0986e-02,  6.7095e-03,  2.5387e-03, -4.2426e-03,\n",
      "         1.0351e-02,  1.8432e-02,  7.7085e-03,  1.7296e-03,  1.1015e-02,\n",
      "         7.3125e-03,  1.4295e-02,  3.4535e-03, -2.0067e-03,  6.2330e-03,\n",
      "        -2.4544e-02, -6.5417e-02, -1.6117e-03,  3.3067e-02,  2.8024e-02,\n",
      "         2.5847e-02,  6.1290e-02,  1.1067e-03,  5.8225e-02, -5.6830e-03,\n",
      "        -9.6139e-03,  4.1084e-03,  2.8468e-03,  2.8690e-03,  4.8782e-03,\n",
      "         1.7971e-03,  7.2268e-03,  1.2724e-02,  1.2109e-02,  1.2295e-02,\n",
      "         2.0615e-02, -7.3548e-03,  6.6262e-03,  1.1460e-02, -1.1202e-03,\n",
      "         1.9617e-02,  2.0194e-02, -6.6859e-03,  2.5539e-02,  2.5974e-02,\n",
      "        -3.8122e-03,  1.1428e-02, -8.2627e-03,  2.1842e-02, -1.8367e-03,\n",
      "         8.7154e-03, -4.1218e-04,  6.0989e-03,  5.6977e-03,  4.5867e-03,\n",
      "         1.1955e-02,  7.8972e-03,  1.0847e-01, -3.4330e-02, -1.4065e-02,\n",
      "         6.0828e-02,  3.9322e-03,  5.6907e-02, -3.9564e-02, -5.7607e-02,\n",
      "         3.3738e-02, -7.4693e-02,  1.0804e-02,  6.9896e-02,  6.3822e-02,\n",
      "         4.5483e-02,  4.2162e-02,  2.8971e-02,  8.0715e-02, -1.0907e-02,\n",
      "         4.3565e-02,  4.1903e-02,  4.5346e-02,  5.6384e-02, -3.1787e-02,\n",
      "        -2.4554e-02, -1.1631e-02, -1.8420e-02, -7.9136e-03,  1.4328e-02,\n",
      "        -1.1022e-03,  5.6215e-03, -2.4600e-03,  9.3936e-03,  8.6762e-03,\n",
      "         6.3847e-03,  5.4403e-03, -4.5550e-03,  4.0385e-03,  1.5101e-03,\n",
      "        -3.3205e-02, -1.6908e-03,  2.9228e-02,  4.6394e-02, -1.7186e-02,\n",
      "        -6.1710e-02, -6.7518e-02,  2.2690e-02, -7.7493e-02, -6.0875e-02,\n",
      "        -4.4283e-02,  1.0795e-01,  4.6856e-02,  5.0792e-02, -1.0831e-01,\n",
      "        -9.9388e-02,  5.5592e-02, -3.2154e-02, -5.1327e-02, -5.0026e-02,\n",
      "         3.2255e-03, -9.3441e-02,  5.1527e-02,  4.9430e-02,  1.3115e-02,\n",
      "         3.4426e-02,  4.5141e-02,  5.7006e-02,  8.8703e-02,  3.4179e-02,\n",
      "         1.2884e-02,  4.7532e-03, -5.6560e-03, -8.0159e-04,  5.7667e-03,\n",
      "         5.3320e-03,  7.5515e-03,  5.2018e-03,  3.9514e-03,  1.4746e-02,\n",
      "        -2.2421e-02,  3.3086e-02, -6.0748e-02,  2.5221e-03, -3.9435e-02,\n",
      "         6.9950e-02,  6.6597e-02,  5.2598e-03,  1.0841e-02, -7.6456e-03,\n",
      "        -1.4607e-02, -2.8777e-02,  7.2116e-02, -6.7748e-04, -4.3192e-02,\n",
      "        -1.6517e-02,  3.1671e-02, -2.9760e-03,  6.9593e-02,  4.4313e-02,\n",
      "         1.0539e-02,  7.3766e-02, -1.7241e-02,  1.9226e-03,  6.2254e-02,\n",
      "        -1.7971e-02,  2.4594e-02,  2.8044e-02, -6.1073e-02, -1.5184e-02,\n",
      "         2.5894e-02,  1.2423e-01,  3.9128e-02,  1.1853e-01,  6.4675e-03,\n",
      "        -1.8402e-02,  9.8138e-03, -6.9809e-04,  1.8317e-02, -1.9863e-03],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "# Model training.\n",
    "\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    model_1.train() # prep model for training\n",
    "    for data, target, _ in train_loader_lstm:\n",
    "        optimizer.zero_grad() \n",
    "        output, hidden = model_1(data)\n",
    "#         output = output.contiguous().view(-1, 10)\n",
    "#         output = output.contiguous().view(-1, 9)\n",
    "#         target = target.contiguous().view(-1)\n",
    "\n",
    "#         target = target.view(-1).to(torch.float64)\n",
    "        print(output.shape)\n",
    "        print(target.shape)\n",
    "        print(output)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    model_1.eval() # prep model for evaluation\n",
    "    for data, target, _ in val_loader_lstm:\n",
    "        output, hidden = model_1(data)\n",
    "#         output = output.contiguous().view(-1, 10)\n",
    "#         output = output.contiguous().view(-1, 10)\n",
    "#         target = target.contiguous().view(-1)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader_lstm.dataset)\n",
    "    valid_loss = valid_loss/len(val_loader_lstm.dataset)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b943e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lengths[i]):\n\u001b[1;32m---> 13\u001b[0m         prediction\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39margmax(\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     14\u001b[0m prediction_list\u001b[38;5;241m.\u001b[39mappend(prediction)\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "# Get predictions.\n",
    "\n",
    "prediction_list = []\n",
    "count = 0\n",
    "for i, batch in enumerate(dev_loader_lstm):\n",
    "    prediction = []\n",
    "    lengths = []\n",
    "    output, hidden = model_1(batch[0])\n",
    "    for b in batch[0]:\n",
    "        lengths.append((torch.count_nonzero(b).item()))\n",
    "    for i,res in enumerate(output):\n",
    "        for j in range(lengths[i]):\n",
    "            prediction.append(torch.argmax(res[j]).item())\n",
    "    prediction_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b042a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0fefbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
